# Bibliography

## Auto-regression & Language Models

### To Find
- Barenholtz, E. - Publications on reasoning and cognition
- Papers on auto-regressive transformers and their mathematical properties
- Chain-of-thought reasoning papers
- Self-feeding mechanisms in neural networks

## Markov Processes

### To Find
- Classic HMM papers (Baum-Welch, Viterbi)
- Neural Markov models
- Markov property in deep learning
- Temporal dependencies and memory in auto-regressive models

## Complexity Theory

### Key Sources
- Barbour, J. - "The End of Time" (book)
- Barbour, J. - Papers on shape dynamics and complexity
- Video lecture: "Complexity and the Arrow of Time" (https://www.youtube.com/watch?v=q-bImnQ9cmw&t=7426s)
- Barbour's collaborators' work on complexity measures

### To Find
- Mathematical formulations of complexity in Barbour's framework
- Connections to information theory
- Applications to embedding spaces

## Geometric Computation

### Key Sources
- The Gray Cuber (https://thegraycuber.github.io/)
  - Shape-based calculation methods
  - Geometric representations of computation

### To Find
- Papers on geometric deep learning
- N-dimensional shape analysis
- Manifold learning and embeddings
- Topological data analysis

## Synthesis Papers

### To Find
- Papers connecting auto-regression with Markov processes
- Geometric interpretations of neural embeddings
- Complexity measures in machine learning
- Information geometry in neural networks

---

## Notes Format Template

For each paper, create a file in the appropriate subdirectory with:
```
# [Title]
**Authors**: 
**Year**: 
**Source**: 

## Summary
[Brief overview]

## Key Concepts
- 
- 

## Relevance to Project
[How this connects to auto-regressive Markov processes]

## Questions/Ideas
- 
- 

## Quotes
> [Important quotes with page numbers]
```